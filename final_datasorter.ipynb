{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, statistics, os, json, operator, glob\n",
    "from glob import glob\n",
    "import pathlib \n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil \n",
    "import csv\n",
    "# %matplotlib inline\n",
    "\n",
    "# ###########################\n",
    "file_search_term = \".json\"\n",
    "dir_search_term = \"JSON\"\n",
    "element_search_terms = [\"Ta\"] # ['WBe'] # [\"InP\"]\n",
    "model_search_terms = [\"Linear\"] # [\"PRB2019\"] # [\"JPCA2020\"]\n",
    "# ##################\n",
    "if len(model_search_terms) != len(element_search_terms):\n",
    "    print(\"im elegantly crashing cause these two vars need to be the same length.\")\n",
    "\n",
    "csv_columns_str = \"element,model,search_item,rel_path,file,Group\\n\"\n",
    "# ################\n",
    "def pull(json_files):\n",
    "    temp_item1, temp_item2 = 0, 0\n",
    "    with open(json_files) as file:\n",
    "        txt = file.readlines()\n",
    "        if len(txt) == 1:\n",
    "            json_data =json.loads(txt[0])\n",
    "        else:\n",
    "            json_data = json.loads(txt[1])\n",
    "        ## (she will show you later why)\n",
    "        for items in json_data[\"Dataset\"][\"Data\"]:\n",
    "             temp_item1 = items[\"Energy\"]\n",
    "             temp_item2 = items[\"NumAtoms\"]\n",
    "    return temp_item1, temp_item2\n",
    "  \n",
    "# ################\n",
    "collect_str_rows_for_a_csv = []\n",
    "cwd = os.getcwd() \n",
    "for current_dir, sub_dirs, files in os.walk(\".\"):\n",
    "    if \"example_walk\" in current_dir:\n",
    "        continue\n",
    "    for model in model_search_terms:\n",
    "        for element in element_search_terms:\n",
    "            if dir_search_term in current_dir and element in current_dir and model in current_dir:\n",
    "                json_files = [f\"{cwd}/{current_dir}/{f}\" for f in files if file_search_term in f]\n",
    "                for f in json_files:\n",
    "                    need, nitems = pull(f)\n",
    "                    normalized_need = need/nitems\n",
    "                    #print(f, nitems, need, normalized_need)\n",
    "                    just_group = f[f.rfind(\"/\")+1:] \n",
    "                    relpath_json = current_dir[current_dir.rfind(\"/\")+1:]\n",
    "                    relpath_group = relpath_json[relpath_json.rfind(\"/\")+1:]\n",
    "                    row_str = f\"{element},{model},{need},{current_dir},{f},{relpath_group}\\n\"\n",
    "                    collect_str_rows_for_a_csv.append(row_str)    \n",
    "\n",
    "if collect_str_rows_for_a_csv == []:\n",
    "    print(\"!!!! The list is empty and will need to be fixed.\")\n",
    "    exit()\n",
    "            \n",
    "# ##############################\n",
    "csv_name = f'{element}{model}Test2.csv'\n",
    "\n",
    "with open(csv_name, \"w\") as lo:\n",
    "   lo.write(csv_columns_str)\n",
    "   for row in collect_str_rows_for_a_csv:\n",
    "        lo.write(row) \n",
    "         \n",
    "# #####################################\n",
    "data = pd.read_csv(csv_name)\n",
    "\n",
    "D = data.sort_values(\"search_item\").reset_index(drop=True)\n",
    "desired_groups = 10\n",
    "num_ebins = len(D)//desired_groups\n",
    "num_rows = D.shape[0]\n",
    "chunks = [D[i:i+num_ebins] for i in range(0,len(D), num_ebins)]\n",
    "file_path_name = f'fitsnap_csvs_for_{element}{model}_{desired_groups}'\n",
    "# ###############################################\n",
    "for i, chunk in enumerate(chunks[:]):\n",
    "    folder_name = 2\n",
    "    chunk_num = i+1\n",
    "    if not os.path.exists(f'./fitsnap_csvs_for_{element}{model}_{desired_groups}'):\n",
    "         os.mkdir(f\"./fitsnap_csvs_for_{element}{model}_{desired_groups}\")\n",
    "    csv_full_name = f'./{file_path_name}/{element}{model}_chunk{chunk_num}.csv'\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    chunk.to_csv(csv_full_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
